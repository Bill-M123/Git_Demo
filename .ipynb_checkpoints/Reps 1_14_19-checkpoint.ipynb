{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we identify party affiliations from voting records?\n",
    "\n",
    "Using the voting record for the Massachusetts house of representatives for the last two years as a base, unstructured learning (kmeans) was applied to a dataset that had only bill names and voting record.  The results were interesting in that there is really very little independent decision making on the part of individual reps and the correlation to party positions is quite high.  \n",
    "\n",
    "The results are somewhat predictable in that two main groups emerge, and when checked against declared party affiliations, Democrats and Republicans are both grouped tightly and easily identifiable.  Most interesting is that the two declared \"independents\" in the House are effectively democrats in terms of voting, and the most \"independent\" when votes are cast are really democratic reps.\n",
    "\n",
    "As an aside, most of the difficulty with this analysis was in the data cleaning stage.  The voting records are only available as PDF files, and the processing of those files is not straight forward.  Multiple packages were tested, and a combination of pdfminer, PyPDF2, and tabula-py was the most effective at scanning the voting tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports, set dataframe with to accomodate large number of reps and bills\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "import io\n",
    "\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "\n",
    "#import io\n",
    "\n",
    "#from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "#from pdfminer.converter import TextConverter\n",
    "#from pdfminer.layout import LAParams\n",
    "#from pdfminer.pdfpage import PDFPage\n",
    "\n",
    "import PyPDF2\n",
    "#from PyPDF2 import PdfFileReader\n",
    "import tabula\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Processing:\n",
    "Examine full PDF file, count total votes, and break file into individual files for ease of conversion with tabula.  It is also necessary to process the vote columns themselves.  Bills have a varying number of positive, negative, abstensions, and late votes.  From an data perspective, the challenge is that the bills don't scan in a uniform fashion and need to be cleaned.\n",
    "\n",
    "Additionally, tabula was unable to scan page 61 and a special action (labeled band-aid) was required to process that page.\n",
    "\n",
    "Finally, individual rep votes are processed into a useful dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Need this for processing page header, bill descriptions, and limited summary information on votes\n",
    "def convert_pdf_to_txt(path):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = io.StringIO()\n",
    "    \n",
    "    retstr =io.BytesIO()\n",
    "    \n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    fp = open(path, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = \"\"\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos = set()\n",
    "\n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages,\n",
    "                                  password=password,\n",
    "                                  caching=caching,\n",
    "                                  check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "    text = retstr.getvalue()\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 215 pages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy [ipykernel_launcher.py:85]\n",
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy [ipykernel_launcher.py:88]\n",
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy [ipykernel_launcher.py:90]\n",
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy [ipykernel_launcher.py:91]\n"
     ]
    }
   ],
   "source": [
    "# Set filename variables\n",
    "filename=\"combined2018_RollCalls.pdf\"\n",
    "path=\"C://Users//bill_//OneDrive//Reps_Data//\"\n",
    "full_name=path+filename\n",
    "problem_pages=[]\n",
    "\n",
    "# Scan number of total votes\n",
    "my_obj=open(full_name,'rb')\n",
    "reader=PyPDF2.PdfFileReader(my_obj)\n",
    "pg_count=reader.numPages\n",
    "print 'Found {} pages.'.format(pg_count)\n",
    "\n",
    "# Read pdf into DataFrame.  Total PDF has been split into individul votes, 1 pdf per vote\n",
    "\n",
    "all_votes_df=pd.DataFrame()\n",
    "\n",
    "for pg in range(1,pg_count):\n",
    "\n",
    "    fname=\"document-page\"+str(pg)+\".pdf\"\n",
    "    full_name=path+fname #laod appropriate vote\n",
    "\n",
    "    df2 = tabula.read_pdf(full_name,pandas_options ={'header': None},pages='all')\n",
    "    df2.fillna('',inplace=True)\n",
    "    \n",
    "    yea_col=[]\n",
    "    nay_col=[]\n",
    "    absent_col=[]\n",
    "    name_col=[]\n",
    "\n",
    "    #  Set up column identification and vote type counts\n",
    "    for c in df2.columns:\n",
    "        entries=list(df2[c].unique())\n",
    "        if 'Y' in entries:\n",
    "            yea_col.append(c)\n",
    "        elif 'N' in entries:\n",
    "            nay_col.append(c)\n",
    "        elif 'X' in entries:\n",
    "            absent_col.append(c)\n",
    "        elif 'P' in entries:\n",
    "            absent_col.append(c)\n",
    "        else:\n",
    "            name_col.append(c)\n",
    "\n",
    "    # Determine column content\n",
    "    yea_col=sorted(list(set(yea_col)))\n",
    "    nay_col=sorted(list(set(nay_col)))\n",
    "    absent_col=sorted(list(set(absent_col)))\n",
    "    name_columns=sorted(list(set(df2.columns).difference(set(yea_col+nay_col+absent_col))))\n",
    "\n",
    "    # Page 61 bandaid\n",
    "    if pg in [61,186,187,188,189]:\n",
    "        \n",
    "        # bandaid to fix names\n",
    "\n",
    "        first_name_col=int(name_columns[0])\n",
    "\n",
    "        def get_name(thing):\n",
    "            '''Accept a thing that is made up of a name, possibly an asterisk, and possibly a vote.  Return only the name.'''\n",
    "            tmp=thing.replace(' *','').split(' ')\n",
    "            tmp=[x for x in tmp if x!= 'Y']\n",
    "            return ' '.join(tmp)\n",
    "\n",
    "        names=map(get_name,df2[first_name_col].values)\n",
    "        \n",
    "        #  Need to process out 'Y' from names and replace appropriately.  Take advantage of fact that\n",
    "        #  no rep name ends in upper case y\n",
    "\n",
    "        bob=df2[first_name_col].apply(lambda x: x.split(' '))\n",
    "        yes_bandaid=[x[-1] if x[-1]=='Y' else '' for x in bob ]\n",
    "\n",
    "        df2[first_name_col]=names\n",
    "        df2.insert(first_name_col+1, 'bandaid', yes_bandaid)\n",
    "        df2.columns=range(len(df2.columns))\n",
    "\n",
    "    new_df=pd.DataFrame()\n",
    "    start=0\n",
    "\n",
    "    # Process Vote columns.  See picture for example of supplield PDF format, but essentially multiple columns of vote\n",
    "    # type for each rep, with typically 4 columns of rep.  Process each column of reps and associated votes, rep names\n",
    "    # added as a column.  \n",
    "    \n",
    "    for i in range(len(name_columns)):\n",
    "        tmp_df=df2.loc[:,(df2.columns>=start)&(df2.columns<=name_columns[i])]\n",
    "        tmp_cols=tmp_df.columns\n",
    "        tmp_df['vote']=''\n",
    "\n",
    "        for v in range(start,name_columns[i]):\n",
    "            tmp_df['vote']=tmp_df['vote']+tmp_df[v]\n",
    "\n",
    "        tmp_df['name']=df2[v+1]\n",
    "        tmp_df.drop(tmp_cols,inplace=True,axis=1)\n",
    "        start=name_columns[i]+1\n",
    "        new_df=new_df.append(tmp_df,ignore_index=True)\n",
    "        \n",
    "    page_num=pg\n",
    "    bob=convert_pdf_to_txt(full_name)\n",
    "    bob=[x for x in bob.split('\\n') if x != '']\n",
    "\n",
    "    # Make debugging easier by pre-labling columns\n",
    "    default=str(page_num)+'_Problem'\n",
    "    bill_num=default\n",
    "    vote_nm=default\n",
    "    yeas=default\n",
    "    no_vote=default\n",
    "    vote_date=default\n",
    "    vote_time=default\n",
    "\n",
    "    #if pg in [66,71,72,103,151,209]:\n",
    "     #   print 40*'#','\\n',pg\n",
    "        \n",
    "    flag=0 \n",
    "    f_yeas=0\n",
    "    f_nays=0\n",
    "    f_no_vote=0\n",
    "    f_date=0\n",
    "    f_num=0\n",
    "    f_name=0\n",
    "    \n",
    "    \n",
    "    for i in range(len(bob)):    #range(20):\n",
    "        if 'YEAS' in bob[i]:\n",
    "            yeas=int(bob[i].split(' ')[0])\n",
    "            f_yeas=1\n",
    "            \n",
    "        if 'NAYS' in bob[i]:\n",
    "            nays=int(bob[i].split(' ')[0])\n",
    "            f_nays=1\n",
    "            \n",
    "        if 'N/V' in bob[i]:\n",
    "            no_vote=int(bob[i].split(' ')[0])\n",
    "            f_no_vote=1\n",
    "            \n",
    "        if '/201' in bob[i]:\n",
    "            vote_date=bob[i].split(' ')[0]\n",
    "            vote_time=bob[i].split(' ')[1]+' '+bob[i].split(' ')[2]\n",
    "            f_date=1\n",
    "\n",
    "        if 'No. ' in bob[i]:\n",
    "            bill_num=int(bob[i].split(' ')[1])\n",
    "            f_num=1\n",
    "            \n",
    "        if ('H.' in bob[i]) or ('S.' in bob[i]) or ('QUORUM' in bob[i]) or ('On suspension' in bob[i])\\\n",
    "            or ('Shall decision of the Chair stand' in bob[i]):\n",
    "            vote_nm=bob[i]\n",
    "            f_name=1\n",
    "        \n",
    "        flag=f_yeas+f_nays+f_no_vote+f_date+f_num+f_name\n",
    "        if flag==6:\n",
    "            break\n",
    "        \n",
    "    flag=0\n",
    "            \n",
    "    new_df['bill_num']=bill_num\n",
    "    new_df['vote_nm']=vote_nm\n",
    "    new_df['no_vote']=no_vote\n",
    "    new_df['yeas']=yeas\n",
    "    new_df['nays']=nays\n",
    "    new_df['vote_date']=vote_date\n",
    "    new_df['vote_time']=vote_time\n",
    "    new_df['page_num']=pg\n",
    "    all_votes_df=all_votes_df.append(new_df,ignore_index=True)\n",
    "\n",
    "    def check_vote_types(thing):\n",
    "        votes=[x for x in thing if (x!='N') and (x!='Y') and (x!='X') and (x!='P') and (x!='')]\n",
    "        vote=sorted(list(votes))\n",
    "                         \n",
    "        if vote==[]:\n",
    "            return ''\n",
    "        \n",
    "        problem_pages.append(pg)\n",
    "        #print 'Issues with vote on page: {}'.format(pg)\n",
    "        return \n",
    "    \n",
    "    check_vote_types(new_df.vote)\n",
    "\n",
    "all_votes_df.to_csv(\"reps_record_1_6_19.csv\",encoding='utf-8',index=False)\n",
    "\n",
    "print \"Had problems on {} pages.  There were {} pages that were read correctly or {:3.0f}% success rate\"\\\n",
    "    .format(len(problem_pages),pg_count-len(problem_pages),(1-float(len(problem_pages))/pg_count)*100)\n",
    "print \"Problem pages were: \"\n",
    "for p in problem_pages:\n",
    "    print p,' ',\n",
    "all_votes_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove problem_pages, convert Y votes to 1 and everything else to 0 (somewhat simplified, but basically, \n",
    "# the rep supports the bill or you doesn't.  Voting present, or late equals no) look at raw data\n",
    "proper_df=all_votes_df.loc[(all_votes_df.page_num.isin(problem_pages)==False),:]\n",
    "sorted(list(proper_df.vote.unique()))\n",
    "proper_df['vote_val']=proper_df.vote.apply(lambda x: 1 if x=='Y' else (-1 if x=='N' else 0))\n",
    "print proper_df.vote_val.mean()\n",
    "proper_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(proper_df.name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a df to look at vote counts per bill\n",
    "#tmp=proper_df.loc[(all_votes_df.page_num.isin([2,3,4,61,85])==0),:]\n",
    "tmp2=proper_df.pivot_table(index='vote_nm',columns=['vote'],values='page_num',aggfunc='count')\n",
    "tmp2.fillna(0,inplace=True)\n",
    "tmp2.transpose()\n",
    "tmp2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rep_col_df=all_votes_df.loc[(all_votes_df.page_num.isin([2,3,4,61,85])==False),:].rename(columns={'name':'rep_name'}).copy()\n",
    "rep_col_df=proper_df.rename(columns={'name':'rep_name'}).copy()\n",
    "rep_col_df['rep_name']=rep_col_df.apply(lambda x: x.rep_name.encode('ascii','ignore').replace(' *',''),axis=1)\n",
    "rep_col_df=rep_col_df.pivot_table(index='rep_name',columns='vote_nm',values='vote_val',aggfunc='max')\n",
    "rep_col_df.fillna(0,inplace=True)\n",
    "rep_col_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply simple unstructured learning to as a first step\n",
    "# in identifying groups of reps\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Initialize Model\n",
    "n_clusters=2\n",
    "model = KMeans(n_clusters=n_clusters)\n",
    "\n",
    "# Fit Model\n",
    "model.fit(rep_col_df)\n",
    "\n",
    "# Prediction on the entire data\n",
    "preds = model.predict(rep_col_df)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_vote=rep_col_df.transpose()\n",
    "corr=da_vote.corr()\n",
    "corr.head(20)\n",
    "plt.hist(corr['Mr. Speaker'].dropna(),bins=10)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print len(corr['Mr. Speaker']),len(rep_col_df.transpose().sum()),len(preds)\n",
    "df_fin=pd.DataFrame(index=corr['Mr. Speaker'].index,columns=['Spkr_Corr','Min_Corr','For_sum','Preds'])\n",
    "df_fin['Spkr_Corr']=corr['Mr. Speaker'].values\n",
    "df_fin['Min_Corr']=corr['Jones'].values\n",
    "df_fin['For_sum']=rep_col_df.transpose().sum().values\n",
    "df_fin['Preds']=preds\n",
    "df_fin['rep_name']=df_fin.index\n",
    "\n",
    "def get_party(name):\n",
    "    \n",
    "    try:\n",
    "        #print name,st_df.loc[st_df.Last_Name==name,'Party']\n",
    "        return st_df.loc[st_df.Last_Name==name,'Party'].values[0]\n",
    "    except:\n",
    "        return 'Unknown'\n",
    "\n",
    "df_fin['Party']=df_fin.rep_name.apply(get_party)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5,5),dpi=100)\n",
    "\n",
    "#Party Setup\n",
    "party_colors=['b','r','g','y']\n",
    "parties=sorted(list(df_fin.Party.unique()))\n",
    "tar_sz=300\n",
    "\n",
    "for c in range(len(parties)):\n",
    "    tmp=df_fin.loc[df_fin.Party==parties[c],:]\n",
    "    plt.scatter(tmp.Min_Corr,tmp.Spkr_Corr,color=party_colors[c],label='{}'.format(parties[c]),alpha=0.25,s=tar_sz)\n",
    "\n",
    "cat_colors=['b','r','g']\n",
    "for c in range(len(set(preds))):\n",
    "    tmp=df_fin.loc[df_fin.Preds==c,:]\n",
    "    plt.scatter(tmp.Min_Corr,tmp.Spkr_Corr,color=cat_colors[c],label='Group {}'.format(c))\n",
    "plt.legend(loc='best',ncol=2)\n",
    "plt.xlabel('Minority Correlation')\n",
    "plt.ylabel('Majority Correlation')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ma_State_Rep_Data:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.url='https://malegislature.gov/People/House'\n",
    "        self.active_reps=self.get_active_reps()\n",
    "        self.rep_list=self.get_rep_list()\n",
    "        self.rep_dict=self.get_rep_dict()\n",
    "        return\n",
    "    \n",
    "    def get_active_reps(self):\n",
    "        '''Access current list of mass state reps.  Return dataframe containing:\n",
    "        first and last names, voting district, county, party, office number and email address'''\n",
    "        \n",
    "        tmp=pd.read_html(self.url)\n",
    "        df=tmp[0]\n",
    "        df=df.loc[df[u'\\n    First Name\\n    \\n    \\n        \\n        \\n        \\n    \\n']!= 'Vacant',:]\n",
    "        df.rename(columns={u'\\n    First Name\\n    \\n    \\n        \\n        \\n        \\n    \\n':'First_Name',\n",
    "                       u'\\n    Last Name\\n    \\n    \\n        \\n        \\n        \\n    \\n':'Last_Name',\n",
    "                       u'\\n    Party\\n    \\n    \\n        \\n        \\n        \\n    \\n':'Party'},\n",
    "                     inplace=True)\n",
    "\n",
    "        df.drop([u'Follow In My Legislature',u'Legislator Photo'],inplace=True,axis=1)\n",
    "        df['County']=df.District.apply(lambda x: x.split(' ')[1])\n",
    "        del tmp\n",
    "        return df[['First_Name','Last_Name','District','County','Party','Room','Phone Number','Email Address']]\n",
    "\n",
    "    def get_rep_list(self):\n",
    "        return sorted(list(self.active_reps['Last_Name']))\n",
    "    def get_rep_dict(self):\n",
    "\n",
    "        tmp=self.active_reps[['First_Name','Last_Name','Party','District']].copy()\n",
    "        tmp['Rep_Key']=tmp['Last_Name'].copy()\n",
    "        \n",
    "        tmp['Rep_Key']=tmp.apply((lambda x: x.Last_Name+','+x.First_Name[0]+'.' if\n",
    "                                   ((x.Last_Name=='Hunt')|(x.Last_Name=='Rogers')|\\\n",
    "                                  (x.Last_Name=='Walsh')) else x.Last_Name),axis=1)\n",
    "        \n",
    "       \n",
    "        tmp.index=tmp.Rep_Key\n",
    "        tmp.drop('Rep_Key',axis=1,inplace=True)\n",
    "        tmp=tmp.transpose()\n",
    "\n",
    "        return tmp.to_dict()\n",
    "\n",
    "    \n",
    "### Initalize st_reps class   \n",
    "st_reps=Ma_State_Rep_Data()\n",
    "st_df=pd.DataFrame(st_reps.get_active_reps())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_df=pd.DataFrame(st_reps.get_active_reps())\n",
    "st_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print st_reps.get_rep_list()\n",
    "tmp=proper_df.rename(columns={'name':'rep_name'}).copy()\n",
    "tmp.rep_name=tmp.rep_name.apply(lambda x: x.replace(' *',''))\n",
    "set(tmp.rep_name).difference(set(st_reps.rep_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
